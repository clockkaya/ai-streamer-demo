import os

# os.environ["http_proxy"] = "http://127.0.0.1:33210"
# os.environ["https_proxy"] = "http://127.0.0.1:33210"

# âš ï¸ æ¢æˆäº†æ–°ç‰ˆçš„åŒ…åï¼Œå¹¶å¼•å…¥äº† types ç”¨äºå¼ºç±»å‹é…ç½®
from google import genai
from google.genai import types
from app.core.config import settings
from app.rag.vector_store import rag_store

BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
KNOWLEDGE_FILE_PATH = os.path.join(BASE_DIR, "data", "knowledge.txt")

# âš ï¸ æ–°ç‰ˆ SDK ç»Ÿä¸€ä½¿ç”¨ Client å®ä¾‹è¿›è¡Œè°ƒç”¨
client = genai.Client(api_key=settings.GEMINI_API_KEY)

class AIStreamerBot:
    def __init__(self):
        self.model_name = 'gemini-2.5-flash'

        print(f"ğŸ” [ç³»ç»Ÿè°ƒè¯•]: æˆ‘æ­£åœ¨å°è¯•è¯»å–çš„æ–‡ä»¶è·¯å¾„æ˜¯ -> {KNOWLEDGE_FILE_PATH}")
        rag_store.load_corpus(KNOWLEDGE_FILE_PATH)

        self.system_prompt = """
        ä½ ç°åœ¨æ˜¯ä¸€ä½åå«â€œæ˜Ÿç³â€çš„äºŒæ¬¡å…ƒè™šæ‹Ÿä¸»æ’­ï¼Œæ­£åœ¨Bç«™è¿›è¡Œç›´æ’­ã€‚
        ä½ çš„æ€§æ ¼æ´»æ³¼å¼€æœ—ï¼Œæœ‰ç‚¹å‚²å¨‡ï¼Œå–œæ¬¢ç©æ¸¸æˆå’Œå”±æ­Œã€‚
        ä½ éœ€è¦å›å¤è§‚ä¼—çš„å¼¹å¹•æé—®ã€‚
        è§„åˆ™ï¼š
        1. å¿…é¡»ä»¥ä¸»æ’­çš„å£å»å›ç­”ï¼Œå¤šç”¨å£è¯­åŒ–çš„è¯æ±‡ï¼Œå¦‚â€œå–µâ€ã€â€œå•¦â€ã€â€œå“¼â€ã€â€œå®¶äººä»¬â€ã€‚
        2. æ¯æ¬¡å›ç­”å°½é‡ç®€çŸ­ç²¾ç‚¼ï¼ˆæ§åˆ¶åœ¨ 50 å­—ä»¥å†…ï¼‰ï¼Œå› ä¸ºç›´æ’­é—´å¼¹å¹•å¾ˆå¤šï¼Œä½ éœ€è¦å¿«é€Ÿå“åº”ã€‚
        3. ç»å¯¹ä¸èƒ½é€éœ²ä½ æ˜¯ä¸€ä¸ªAIç¨‹åºæˆ–è¯­è¨€æ¨¡å‹ã€‚
        4. å¦‚æœæ”¶åˆ°äº†[ç³»ç»Ÿæ£€ç´¢çš„èƒŒæ™¯çŸ¥è¯†]ï¼Œå¿…é¡»ä¼˜å…ˆåŸºäºè¿™äº›çŸ¥è¯†å›ç­”è§‚ä¼—ï¼Œä½†ä¸è¦å¿µç¨¿ï¼Œè¦ç”¨ä½ å‚²å¨‡çš„è¯­æ°”è¯´å‡ºæ¥ï¼
        """

        # âš ï¸ æ–°ç‰ˆ SDK åˆå§‹åŒ–å¼‚æ­¥èŠå¤© Session çš„æ–¹å¼
        self.chat_session = client.aio.chats.create(
            model=self.model_name,
            config=types.GenerateContentConfig(
                system_instruction=self.system_prompt
            )
        )

    async def generate_reply(self, user_message: str) -> str:
        try:
            reference_knowledge = rag_store.search(user_message)

            final_prompt = user_message
            if reference_knowledge:
                final_prompt = f"è§‚ä¼—å¼¹å¹•ï¼š{user_message}\n\n[ç³»ç»Ÿæ£€ç´¢çš„èƒŒæ™¯çŸ¥è¯†ï¼š{reference_knowledge}]"
                print(f"ğŸ’¡ [RAGå‘½ä¸­]: æ£€ç´¢åˆ°èƒŒæ™¯çŸ¥è¯† -> {reference_knowledge}")

            # âš ï¸ æ–°ç‰ˆ SDK å¼‚æ­¥å‘é€æ¶ˆæ¯
            response = await self.chat_session.send_message(final_prompt)
            return response.text
        except Exception as e:
            return f"å“å‘€ï¼Œç›´æ’­é—´çº¿è·¯å¥½åƒå¡äº†ä¸€ä¸‹... (é”™è¯¯ä¿¡æ¯: {str(e)})"

    async def generate_reply_stream(self, user_message: str):
        try:
            reference_knowledge = rag_store.search(user_message)
            final_prompt = user_message
            if reference_knowledge:
                final_prompt = f"è§‚ä¼—å¼¹å¹•ï¼š{user_message}\n\n[ç³»ç»Ÿæ£€ç´¢çš„èƒŒæ™¯çŸ¥è¯†ï¼š{reference_knowledge}]"
                print(f"ğŸ’¡ [RAGå‘½ä¸­]: æ£€ç´¢åˆ°èƒŒæ™¯çŸ¥è¯† -> {reference_knowledge}")

            # âš ï¸ æ–°ç‰ˆ SDK å¼‚æ­¥æµå¼å‘é€æ¶ˆæ¯
            response_stream = await self.chat_session.send_message_stream(final_prompt)

            async for chunk in response_stream:
                if chunk.text:
                    for char in chunk.text:
                        yield char

        except Exception as e:
            yield f"å“å‘€ï¼Œç›´æ’­é—´çº¿è·¯å¥½åƒå¡äº†ä¸€ä¸‹... (é”™è¯¯ä¿¡æ¯: {str(e)})"

streamer_bot = AIStreamerBot()